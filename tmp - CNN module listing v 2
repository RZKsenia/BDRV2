import numpy as np
import tensorflow as tf
import os
import keras

class ConvNN(object):
    """
    Класс реализации сети CNN с использованием API-интерфейса Layers
    из TensorFlow.
    """
    def __init__(self, batchsize = 64, epochs = 20, leraning_rate = 1e-4,
                 dropout_rate=0.5, shuffle=True, random_seed=None):
        np.random.seed(random_seed)
        self.batchsize = batchsize
        self.epochs = epochs
        self.learning_rate = leraning_rate
        self.dropout_rate = dropout_rate
        self.shuffle = shuffle

        g = tf.Graph()
        with g.as_default():
            # установка начального случайного значения
            tf.random.set_seed(random_seed)

            # построение сети
            self.build()

            # объект инициализатора
            self.init_op = tf.compat.v1.global_variables_initializer()

            # объект сохранения
            self.saver = tf.compat.v1.train.Saver()

            # создание сеанса
            self.sess = tf.compat.v1.Session(graph = g)

    def batch_generator(X, y, batch_size=64, shuffle=False, random_seed=None):
        # Эта функция возвращает генератор с кортежем для пары образцов,
        # например, данные Х и метки у.
        idx = np.arange(y.shape[0])

        if shuffle:
            rng = np.random.RandomState(random_seed)
            rng.shuffle(idx)
            X = X[idx]
            y = y[idx]

        for i in range(0, X.shape[0], batch_size):
            yield (X[i:i + batch_size, :], y[i:i + batch_size])

    def build(self):
        """
        Функция построения модели
        :return:
        """
        # заполнители для Х и у:
        tf_x = tf.compat.v1.placeholder(tf.float32,
                              shape=[None,784],
                              name='tf_x')
        tf_y = tf.compat.v1.placeholder(tf.int32,
                              shape=[None],
                              name='tf_y')
        is_train = tf.compat.v1.placeholder(tf.bool,
                                  shape=(),
                                  name='is_train')

        # изменение формы Х на четырёхмерный тензор
        # [размер пакета, ширина, высота, 1]
        tf_x_image = tf.reshape(tf_x, shape=[-1, 250, 250, 1],
                                name='input_2d_images')
        # унитарное кодирование
        tf_y_onehot = tf.one_hot(indices=tf_y, depth=10,
                                 dtype=tf.float32,
                                 name='input_y_onehot')

        # первый слой: свёрточный слой 1
        h1 = tf.keras.layers.Conv2D(filters=32,
                                    kernel_size=(5, 5),
                                    input_shape=tf_x_image,
                                    activation=tf.compat.v1.nn.relu)

        # объединение по максимуму
        h1_pool = tf.keras.layers.MaxPooling2D(h1,
                                          pool_size=(2,2),
                                          strides=(2,2))

        # второй слой: свёрточный слой 2
        h2 = tf.keras.layers.Conv2D(input_shape=h1_pool,
                              kernel_size=(5, 5),
                              filters=64,
                              activation = tf.compat.v1.nn.relu)

        # объединение по максимуму
        h2_pool = tf.keras.layers.MaxPooling2D(input_shape=h2,
                                          pool_size=(2, 2),
                                          strides=(2, 2))

        # третий слой: полносвязный слой
        input_shape = h2_pool.get_shape().as_list()
        n_input_units = np.prod(input_shape[1:])
        h2_pool_flat = tf.reshape(input_shape=h2_pool,
                                  shape=[-1, n_input_units])
        h3 = keras.layers.Dense(input_shape=h2_pool_flat, units=1024,
                             activation=tf.compat.v1.nn.relu)

        # отключение
        h3_drop = tf.keras.layers.dropout(input_shape=h3,
                                  rate=self.dropout_rate,
                                  training=is_train)

        # четвёртый слой
        h4 = tf.keras.layers.Dense(input_shape=h3_drop, units=10, activation=None)

        # прогнозирование
        predictions = {'propabilities':tf.nn.softmax(h4, name='propabilities'),
                       'labels':tf.cast(tf.argmax(h4, axis=1), tf.int32, name='labels')}

        # функция потерь и оптимизация
        cross_entropy_loss = tf.compat.v1.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h4, labels=tf_y_onehot),
                                            name='cross_entropy_loss')

        # оптимизатор
        optimizer = tf.compat.v1.train.AdamOptimizer(self.learning_rate)
        optimizer = optimizer.minimize(cross_entropy_loss, name='train_op')

        # вычисление правильности прогнозирования
        correct_predictions = tf.equal(predictions['labels'],
                                       tf_y, name='correct_preds')

        accuracy = tf.reduce_mean (tf.cast(correct_predictions, tf.float32),
                                   name='accuracy')

    def save(self, epoch, path='./tflayers-model/'):
        """
        Функция сохранения обученной модели
        :param epoch:
        :param path:
        :return:
        """
        if not os.path.isdir(path):
            os.makedirs(path)

        print('Сохранение модели в %s' % path)
        self.saver.save(self.sess,
                        os.path.join(path, 'model.ckpt'),
                        global_step=epoch)

    def load(self, epoch, path):
        """
        Функция загрузки сохранённой модели
        :param epoch:
        :param path:
        :return:
        """
        print('Загрузка модели из %s' % path)
        self.saver.restore(self.sess,
                           os.path.join(path, 'model.ckpt-%d'%epoch))

    def train(self, training_set,
              validation_set=None,
              initialize=True):
        """
        Функция обучения модели
        :param training_set:
        :param validation_set:
        :param initialize:
        :return:
        """
        # инициализация переменных
        if initialize:
            self.sess.run(self.init_op)
        self.train_cost_ = []
        X_data = np.array(training_set[0])
        y_data = np.array(training_set[1])

        for epoch in range(1, self.epochs+1):
            batch_gen = self.batch_generator(X_data, y_data, shuffle = self.shuffle)

            avg_loss = 0.0

            for i, (batch_x, batch_y) in enumerate(batch_gen):
                feed = {'tf_x:0' : batch_x,
                        'tf_y:0' : batch_y,
                        'is_train:0' : True} # для отключения

                loss, _ =self.sess.run(
                    ['cross_entropy_loss:0', 'train_op'],
                    feed_dict = feed)

                avg_loss += loss

                print ('Эпоха %002d: Средние потери при обучении: %7.3f' % (epoch, avg_loss), end=' ')

                if validation_set is not None:
                    feed = {'tf_x:0': batch_x,
                            'tf_y:0': batch_y,
                            'is_train:0': False}  # для отключения

                    valid_acc = self.sess.run('accuracy:0', feed_dict=feed)
                    print('Правильность при проверке: %7.3f' % valid_acc)
                else:
                    print()

    def predict(self, X_test, return_proba=False):
        """
        Функция вырабатывания прогнозов на испытательном наборе
        :param X_test:
        :param return_proba:
        :return:
        """
        feed = {'tf_x:0' : X_test,
                'is_train:0' : False} # для отключения

        if return_proba:
            return self.sess.run('probabilities:0',
                                 feed_dict=feed)
        else:
            return self.sess.run('labels:0',
                                 feed_dict=feed)